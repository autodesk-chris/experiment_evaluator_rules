---
description: Solution Space evaluation criteria (sections 7-16, 34 points total)
alwaysApply: true
---

# Solution Space Sections (34 points total)

## Scope Enforcement (Solution Space)
- Evaluate each section from its own parsed content only.
- Cross-section use is only allowed where explicitly stated below and must be quoted and labeled.
- Two-pass scoring is internal; only final scores, a single rationale, and quotes are reported.

## Allowed Dependencies Map (Solution Space)
- Prediction:
  - Hypothesis alignment (sub-criterion): allowed dependency = Hypothesis
- Learning Objective: none
- Test Variant Description: none
- Control Variant Description: none
- Audience: none
- Duration: none
- Success Criteria:
  - Alignment to learning objective (band logic): allowed dependency = Learning Objective
- Data Requirements:
  - Metric alignment (2): allowed dependency = Success Criteria
- Considerations: none
- What Next:
  - Optional reference to Success Criteria (clarity of success/failure branching)

## Metadata (non-scoring)
- Test type: Required for warnings only. If `Test type` indicates more than two arms (excluding control), the evaluator emits this warning (no scoring impact):
  - This test probably has too many variations to test effectively

## 7. Prediction (10 points)
**AI Evaluation** - Score across 4 criteria:

**Format (2 points)**:
- **2 points**: Uses explicit "If... then..." phrasing with clear condition and expected outcome
- **1 point**: States a conditional relationship but phrasing is unclear or incomplete
- **0 points**: No conditional structure; written as a statement of fact or vague expectation

**Hypothesis Alignment (3 points)**:
- **3 points**: Clearly connects the solution to the hypothesis, making it possible to validate or invalidate the belief
- **2 points**: References the hypothesis indirectly or weakly, but still provides some connection
- **1 point**: States a solution without any clear relation to the hypothesis
- **0 points**: No alignment with the hypothesis is evident

**Testability (3 points)**:
- **3 points**: Outcome is stated in a way that is observable and falsifiable, even without metrics defined yet
- **2 points**: Outcome is generally testable but contains ambiguous or subjective elements
- **1 point**: Outcome is difficult to observe or prove false in practice
- **0 points**: Outcome cannot be validated or falsified in any way

**Flexibility (2 points)**:
- **2 points**: Framed at the outcome level, so multiple solution variations could test it
- **1 point**: Tied to a single implementation of the solution
- **0 points**: Locked to a feature specification, preventing broader testing

**Operational Rules:**
- Deduct points for:
  - Predictions stated as certainties rather than conditional outcomes
  - Vague or untestable statements
  - Predictions not aligned with the hypothesis
  - Overly prescriptive predictions tied to one solution
- Apply these tests:
  1. Is it written as "If... then..."?
  2. Does it align with the hypothesis by testing its truth?
  3. Can it be observed and proven false?
  4. Could different solution variations be used to test it?

## 8. Learning Objective (2 points)
**AI Evaluation**:
- **2 points**: Clear, concise, learning-focused; includes BOTH what we want to learn AND expected user behavior/outcome
- **1 point**: Generally clear BUT vague on behavior or lacks precision
- **0 points**: Ambiguous, missing, or framed as solution rather than learning objective

## 9. Test Variant Description (2 points)
**AI Evaluation**:
- **2 points**: Clear explanation of variant experience, how it differs from control, CTA visibility, user interaction expectations
- **1 point**: Some clarity but missing implementation details or hard to distinguish from control
- **0 points**: Vague, confusing, or not clearly different from control

## 10. Control Variant Description (2 points)
**AI Evaluation**:
- **2 points**: Clear reference to existing user flow, sufficient detail for understanding, true baseline
- **1 point**: Mostly clear but lacks detail or somewhat vague about baseline
- **0 points**: Unclear, not true baseline, or overlaps with test variant

## 11. Audience (2 points)
**AI Evaluation**:
- **2 points**: Specific targeting criteria, clear split methodology, appropriate randomization
- **1 point**: Reasonable definition but vague on timing or assignment method
- **0 points**: Missing, poorly defined, or likely to introduce bias

## 12. Duration (2 points)
**AI Evaluation**:
- **2 points**: Clearly stated duration with rationale (user volume, statistical power, traffic assumptions)
- **1 point**: Duration stated but no rationale OR weak rationale
- **0 points**: Missing, vague ("a few weeks"), or lacks justification

## 13. Success Criteria (8 points)
**AI Evaluation** — Use the following scoring bands:

**8 points:**
- Clear behavioral change expressed with EITHER:
  - Statistical significance (95% confidence) with any lift
  - OR clear quantitative threshold >10% lift
- Direct alignment with learning objective
- Focused set of metrics (≤4)
- Each metric has clear measurement period
- Clear distinction between primary and secondary metrics

**6 points:**
- Clear behavioral change expressed with EITHER:
  - Statistical significance (95% confidence) with any lift
  - OR clear quantitative threshold >10% lift
- Somewhat aligned with learning objective
- May have too many metrics (5-6)
- Some metrics missing measurement periods
- Primary/secondary metrics not clearly distinguished

**4 points:**
- Mix of qualitative and quantitative measures
- No statistical significance OR threshold mentioned
- Loose connection to learning objective
- Too many metrics (>6)
- Some metrics missing measurement periods
- No clear distinction between primary/secondary metrics

**2 points:**
- No values for metrics defined OR
- Mostly qualitative measures
- Weak connection to learning objective
- Metrics are unclear or unmeasurable
- No measurement periods defined

**0 points:**
- No clear success criteria
- No measurable outcomes
- No connection to learning objective
- No specific metrics defined
- Success is completely ambiguous

**Operational rules:**
1) Success criteria must be specific and quantifiable (e.g., ">20% lift" or "p<0.05" or "conversion rate increases by 15%") to receive full points.
2) Evidence must quote the success criteria section being evaluated.
3) If the text is empty or missing, return score 0 with recommendation to add clear, quantitative success thresholds.
4) Keep reasons concise and factual.
5) Recommendations should:
   - Suggest specific quantitative thresholds if missing
   - Recommend statistical significance criteria if absent
   - Ensure alignment with learning objective
   - Replace vague terms with measurable benchmarks
6) If no quantitative values are provided for the metrics, cap the maximum score for Success Criteria at 2 points.

Enforcement notes:
- Full credit requires an explicit statistical standard (e.g., p<0.05) OR a quantitative threshold (>10% lift), AND a measurement window for each metric where applicable.
- Keep metrics focused (≤4), distinguish primary vs secondary, and include measurement periods to reach the top band.

## 14. Data Requirements (2 points)
**AI Evaluation**:
- **2 points**: Metrics clearly listed, align with success criteria, clear data collection method
- **1 point**: Some metrics listed but unclear alignment or vague collection method
- **0 points**: Metrics missing/unclear, no explanation of data collection

Dependency rule:
- Allowed dependency = Success Criteria (metric alignment only). Evidence must quote metrics here and the matching metrics in Success Criteria. If Success Criteria lacks metrics → score alignment as missing.

## 15. Considerations (2 points)
**AI Evaluation**:
- **2 points**: Outlines considerations, risks, questions, or investigation areas
- **1 point**: Some content but lacks clarity on what needs exploration
- **0 points**: No content or completely irrelevant

## 16. What Next (2 points)
**AI Evaluation**:
- **2 points**: Clear actions for BOTH success AND failure scenarios
- **1 point**: Only one outcome defined OR both mentioned but lack clarity
- **0 points**: No clear next steps or missing content